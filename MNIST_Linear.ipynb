{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" mnist\n",
    "    model\n",
    "    test \"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Placeholders\n",
    "# X <- 28 * 28 size input data\n",
    "# Y <- (0~9) labeled data\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 28*28], name = 'X')\n",
    "Y = tf.placeholder(tf.int64, shape = [None], name = 'Y')\n",
    "Y_onehot = tf.one_hot(Y, 10, axis=1)\n",
    "\n",
    "# Set Variables\n",
    "# W <- 784 * 10 variables\n",
    "# B <- 1 *10 Biases\n",
    "\n",
    "W = tf.Variable(tf.zeros([28*28, 10]))\n",
    "B = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# Set Linear Model\n",
    "# Y_pred = X * W(matmul) + B\n",
    "\n",
    "Y_pred = tf.matmul(X,W) + B\n",
    "\n",
    "# Set Loss Function\n",
    "# Using Softmax Algorithm\n",
    "# get reduce_mean & use logits(not softmax)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Y_pred, labels=Y_onehot))\n",
    "\n",
    "# Set Accuracy Function\n",
    "# Set softmax\n",
    "\n",
    "softmax = tf.nn.softmax(logits=Y_pred)\n",
    "correct = tf.equal(tf.argmax(softmax,1), tf.argmax(Y_onehot,1))\n",
    "acc = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "\n",
    "# Set Trainer & Optimizer\n",
    "\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.05)\n",
    "optimizer = trainer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading & Normalization\n",
    "# image file has pixel data from 0016 -> reshape(60000,28,28), float\n",
    "# label file has label data from 0008 -> reshape(60000), int\n",
    "\n",
    "fd = open('./mnist/train-images.idx3-ubyte')\n",
    "images = np.fromfile(file=fd, dtype=np.uint8)\n",
    "images = images[16:].reshape([60000,28*28]).astype(np.float)\n",
    "images = images/255.\n",
    "\n",
    "#print(images[1,])\n",
    "fd = open('./mnist/train-labels.idx1-ubyte')\n",
    "labels = np.fromfile(file=fd, dtype=np.uint8)\n",
    "labels = labels[8:].reshape([60000]).astype(np.int)\n",
    "\n",
    "# Test Data Loading\n",
    "fd = open('./mnist/t10k-images.idx3-ubyte')\n",
    "t_images = np.fromfile(file=fd, dtype=np.uint8)\n",
    "t_images = t_images[16:].reshape([10000,28*28]).astype(np.float)\n",
    "t_images = t_images/255.\n",
    "\n",
    "fd = open('./mnist/t10k-labels.idx1-ubyte')\n",
    "t_labels = np.fromfile(file=fd, dtype=np.uint8)\n",
    "t_labels = t_labels[8:].reshape([10000]).astype(np.int)\n",
    "\n",
    "# Initialize TF Session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Variables Initialize\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    accuracy = 0\n",
    "    \n",
    "    # Epoch Loop\n",
    "    batch_size = 1000\n",
    "    batch_count = 60000 // batch_size\n",
    "    for epoch in range(50):\n",
    "        \n",
    "        total_loss = 0\n",
    "        total_accuracy = 0.0\n",
    "        # mini-batch Loop\n",
    "        for i in range(batch_count):\n",
    "            # Set batch index\n",
    "            batch_index =  i * batch_size\n",
    "            \n",
    "            # Set mini-batch data-set\n",
    "            img = np.reshape(images[batch_index:batch_index+batch_size], [batch_size,28*28])\n",
    "            label = labels[batch_index:batch_index+batch_size]\n",
    "            \n",
    "            # Session Run(Trainer Update)\n",
    "            _, loss_v = sess.run([optimizer,loss], feed_dict={X:img,Y:label})\n",
    "            \n",
    "\n",
    "            # Get total_loss & accuracy\n",
    "            total_loss += loss_v\n",
    "    \n",
    "        print('total_loss & acc : ',total_loss, acc.eval(session=sess, feed_dict = {X:img,Y:label}))\n",
    "        print('Test Accuracy : ', acc.eval(session=sess, feed_dict={X:t_images,Y:t_labels}) )\n",
    "        \n",
    "\n",
    "        trained_W, trained_B = sess.run([W,B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.67565306e-02   4.26492700e-06   1.31802658e-02   2.01890386e-02\n",
      "    5.51746871e-05   9.02072233e-01   4.16894728e-02   5.60397849e-04\n",
      "    5.42920108e-03   6.34207736e-05]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import scipy.misc\n",
    "\n",
    "tr_trained_W = np.transpose(trained_W)\n",
    "\n",
    "tr_trained_W = (tr_trained_W - np.mean(tr_trained_W)) / np.std(tr_trained_W) \n",
    "\n",
    "tr_trained_W =(tr_trained_W+1)/2\n",
    "\n",
    "tr_trained_W = (tr_trained_W * 255).reshape([10,28,28])\n",
    "\n",
    "\n",
    "test_img = scipy.misc.imread('testimage1.jpg')\n",
    "test_img = test_img / 255.\n",
    "\n",
    "test_img = np.reshape(test_img, [1,784])\n",
    "\n",
    "\n",
    "# print(test_img[0])\n",
    "test_v = np.matmul(test_img, trained_W) + trained_B\n",
    "\n",
    "softmax_test_v = tf.nn.softmax(test_v)\n",
    "\n",
    "ans = tf.argmax(softmax_test_v,1)\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    \n",
    "    print(sess.run(softmax_test_v))\n",
    "    print(np.argmax(sess.run(softmax_test_v)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-0.19.1-cp27-cp27mu-manylinux1_x86_64.whl (45.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 45.0MB 38kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /home/user01/anaconda2/envs/tensorflow/lib/python2.7/site-packages (from scipy)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-0.19.1\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-4.2.1-cp27-cp27mu-manylinux1_x86_64.whl (5.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.8MB 320kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting olefile (from Pillow)\n",
      "  Downloading olefile-0.44.zip (74kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 7.1MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: olefile\n",
      "  Running setup.py bdist_wheel for olefile ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/user01/.cache/pip/wheels/20/58/49/cc7bd00345397059149a10b0259ef38b867935ea2ecff99a9b\n",
      "Successfully built olefile\n",
      "Installing collected packages: olefile, Pillow\n",
      "Successfully installed Pillow-4.2.1 olefile-0.44\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.misc.imsave('0.jpg',tr_trained_W[0])\n",
    "scipy.misc.imsave('1.jpg',tr_trained_W[1])\n",
    "scipy.misc.imsave('2.jpg',tr_trained_W[2])\n",
    "scipy.misc.imsave('3.jpg',tr_trained_W[3])\n",
    "scipy.misc.imsave('4.jpg',tr_trained_W[4])\n",
    "scipy.misc.imsave('5.jpg',tr_trained_W[5])\n",
    "scipy.misc.imsave('6.jpg',tr_trained_W[6])\n",
    "scipy.misc.imsave('7.jpg',tr_trained_W[7])\n",
    "scipy.misc.imsave('8.jpg',tr_trained_W[8])\n",
    "scipy.misc.imsave('9.jpg',tr_trained_W[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!gimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named mnist_data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-6bbff0d2d0cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmnist_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_mist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_mnist_t10k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named mnist_data"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "from mnist_data import load_mist, load_mnist_t10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
